# src/agent/nodes.py
import datetime
import logging
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.output_parsers import StrOutputParser

# Importy z nÃ¡Å¡ho projektu
from src.agent.models import GrantFinderState, GrantAnalysis, OptimizedQueries
from src.config import get_llm, get_search_tool

# ZÃ­skanie loggera pre tento modul. KonfigurÃ¡cia (setup) prebehne v main.py.
logger = logging.getLogger(__name__)

# GlobÃ¡lne premennÃ© pre nÃ¡stroje (budÃº inicializovanÃ© cez initialize_tools)
llm = None
search_tool = None

def initialize_tools():
    """Inicializuje globÃ¡lne nÃ¡stroje (LLM a Search). VolÃ¡ sa z create_graph()."""
    global llm, search_tool
    # Skontrolujeme, Äi uÅ¾ boli inicializovanÃ©
    if llm is None or search_tool is None:
        logger.info("Inicializujem nÃ¡stroje (LLM, Tavily)...")
        try:
            llm = get_llm()
            search_tool = get_search_tool()
            logger.info("âœ… NÃ¡stroje ÃºspeÅ¡ne inicializovanÃ©.")
        except ValueError as e:
            # Logujeme chybu a propagujeme ju Äalej (zachytÃ­ ju main.py)
            logger.error(f"âŒ Chyba pri inicializÃ¡cii nÃ¡strojov: {e}")
            raise

# --- Uzol 1: Query Optimizer ---
def node_query_optimizer(state: GrantFinderState) -> dict:
    logger.info("\n--- KROK 1: OptimalizÃ¡cia dopytov ---")
    user_query = state["user_query"]
    
    # ZÃ­skame aktuÃ¡lny a budÃºci rok pre lepÅ¡ie vyhÄ¾adÃ¡vanie
    current_year = datetime.date.today().year
    next_year = current_year + 1

    system_prompt = f"""
    Si expert na vyhÄ¾adÃ¡vanie akademickÃ½ch grantovÃ½ch prÃ­leÅ¾itostÃ­ pre humanitnÃ© vedy (teolÃ³gia, filozofia, etika, religionistika).
    Analyzuj poÅ¾iadavku pouÅ¾Ã­vateÄ¾a a vygeneruj 4 aÅ¾ 6 Å¡pecifickÃ½ch, optimalizovanÃ½ch dopytov pre internetovÃ½ vyhÄ¾adÃ¡vaÄ.
    
    DÃ´leÅ¾itÃ© pravidlÃ¡:
    1. Pokry rÃ´zne regiÃ³ny: Slovensko (SK), EÃš, GlobÃ¡lne.
    2. Pre SK pouÅ¾Ã­vaj slovenÄinu a zahrÅˆ kÄ¾ÃºÄovÃ© inÅ¡titÃºcie (napr. APVV, VEGA, KEGA).
    3. Pre EÃš/GlobÃ¡lne pouÅ¾Ã­vaj angliÄtinu a zahrÅˆ programy (napr. Horizon Europe, ERC grants).
    4. Zameraj sa na aktuÃ¡lne alebo budÃºce vÃ½zvy (pouÅ¾i roky {current_year}/{next_year}).
    
    Odpovedz presne podÄ¾a definovanej Pydantic schÃ©my (OptimizedQueries).
    """
    
    # VyuÅ¾ijeme Structured Output
    structured_llm_optimizer = llm.with_structured_output(OptimizedQueries)
    
    result = structured_llm_optimizer.invoke(
        [
            ("system", system_prompt),
            ("human", f"PoÅ¾iadavka pouÅ¾Ã­vateÄ¾a: {user_query}")
        ]
    )
    
    queries = result.queries
    logger.info(f"VygenerovanÃ© dopyty: {queries}")
    return {"optimized_queries": queries}

# --- Uzol 2: Search Executor ---
def node_search_executor(state: GrantFinderState) -> dict:
    logger.info("\n--- KROK 2: VyhÄ¾adÃ¡vanie ---")
    queries = state["optimized_queries"]
    all_results = []
    
    for query in queries:
        if not isinstance(query, str) or not query.strip(): continue
        
        logger.info(f"VyhÄ¾adÃ¡vam: '{query}'...")
        try:
            results = search_tool.invoke({"query": query})
            for res in results:
                all_results.append({
                    "title": res.get("title"),
                    "url": res.get("url"),
                    "content": res.get("content", "")
                })
        except Exception as e:
            # Logujeme chybu aj so stack trace (exc_info=True) a pokraÄujeme Äalej
            logger.error(f"Chyba pri vyhÄ¾adÃ¡vanÃ­ dopytu '{query}': {e}", exc_info=True)
            continue

    logger.info(f"CelkovÃ½ poÄet nÃ¡jdenÃ½ch surovÃ½ch vÃ½sledkov: {len(all_results)}")
    return {"search_results": all_results}

# --- Uzol 3: Grant Analyst ---
def node_grant_analyst(state: GrantFinderState) -> dict:
    logger.info("\n--- KROK 3: AnalÃ½za a extrakcia (Structured Output) ---")
    results = state["search_results"]
    user_query = state["user_query"]

    if not results:
        logger.info("Å½iadne vÃ½sledky na analÃ½zu.")
        return {"structured_grants": []}

    # Nakonfigurujeme LLM pre Structured Output
    structured_llm_analyst = llm.with_structured_output(GrantAnalysis)

    # PripravÃ­me vÃ½sledky pre LLM (optimalizÃ¡cia pre kontextovÃ© okno)
    results_str = ""
    MAX_CONTENT_LEN = 600
    MAX_RESULTS_TO_ANALYZE = 15

    for i, res in enumerate(results[:MAX_RESULTS_TO_ANALYZE]):
        content = res.get('content', '')
        if content:
            content = content[:MAX_CONTENT_LEN] + "..." if len(content) > MAX_CONTENT_LEN else content
        
        results_str += f"[{i+1}] Title: {res.get('title')}\nURL: {res.get('url')}\nContent Snippet: {content}\n\n---\n\n"

    system_prompt = """
    Si vÃ½skumnÃ½ analytik Å¡pecializujÃºci sa na humanitnÃ© vedy (teolÃ³gia, filozofia, etika, religionistika). 
    Tvojou Ãºlohou je analyzovaÅ¥ poskytnutÃ© vÃ½sledky vyhÄ¾adÃ¡vania a extrahovaÅ¥ relevantnÃ© grantovÃ© prÃ­leÅ¾itosti podÄ¾a definovanej schÃ©my (GrantInfo).

    PravidlÃ¡ filtrovania:
    1. **PrÃ­sna relevancia:** ZahrÅˆ iba vÃ½zvy priamo relevantnÃ© pre zadanÃ© odbory alebo pÃ´vodnÃº poÅ¾iadavku pouÅ¾Ã­vateÄ¾a.
    2. **Ignoruj irelevantnÃ½ obsah:** VylÃºÄ novinovÃ© ÄlÃ¡nky, blogy, vÅ¡eobecnÃ© strÃ¡nky univerzÃ­t alebo archÃ­vne/neaktuÃ¡lne/uzavretÃ© vÃ½zvy.
    3. **Interdisciplinarita:** Akceptuj vÃ½zvy z inÃ½ch oblastÃ­ (napr. AI), len ak majÃº jasne definovanÃ½ presah do humanitnÃ½ch vied (napr. Etika AI).
    4. **PresnosÅ¥ extrakcie:** Extrahuj informÃ¡cie Äo najpresnejÅ¡ie. Ak deadline nie je explicitne uvedenÃ½ v snippete, pouÅ¾i 'NeznÃ¡my'.
    """
    
    # Spustenie analÃ½zy
    try:
        analysis_result = structured_llm_analyst.invoke(
            [
                ("system", system_prompt),
                ("human", f"PÃ´vodnÃ¡ poÅ¾iadavka: {user_query}\n\nAnalyzuj tieto vÃ½sledky vyhÄ¾adÃ¡vania a extrahuj relevantnÃ© granty:\n\n{results_str}")
            ]
        )
    except Exception as e:
        logger.error(f"Chyba pri analÃ½ze LLM alebo parsovanÃ­ vÃ½stupu: {e}", exc_info=True)
        return {"structured_grants": []} # VrÃ¡time prÃ¡zdny zoznam v prÃ­pade chyby

    # Konverzia Pydantic objektov na slovnÃ­ky (pouÅ¾Ã­vame .dict() pre Pydantic V1 kompatibilitu)
    structured_grants_list = [grant.dict() for grant in analysis_result.grants]
    logger.info(f"PoÄet extrahovanÃ½ch relevantnÃ½ch grantov: {len(structured_grants_list)}")
    return {"structured_grants": structured_grants_list}

# --- Uzol 4: Report Generator ---
def node_report_generator(state: GrantFinderState) -> dict:
    logger.info("\n--- KROK 4: Generovanie reportu ---")
    grants = state["structured_grants"]
    user_query = state["user_query"]

    if not grants:
        report = "BohuÅ¾iaÄ¾, na zÃ¡klade aktuÃ¡lnych informÃ¡ciÃ­ sa mi nepodarilo nÃ¡jsÅ¥ Å¾iadne relevantnÃ© otvorenÃ© grantovÃ© vÃ½zvy pre vaÅ¡u poÅ¾iadavku. OdporÃºÄam skÃºsiÅ¥ Å¡irÅ¡ie alebo inak formulovanÃ© zadanie."
        return {"final_report": report}

    system_prompt = """
    Si profesionÃ¡lny AI asistent pre akademickÃ½ch pracovnÃ­kov. Tvojou Ãºlohou je vytvoriÅ¥ prehÄ¾adnÃ½, detailnÃ½ a profesionÃ¡lne pÃ´sobiaci report o nÃ¡jdenÃ½ch grantovÃ½ch prÃ­leÅ¾itostiach.
    PÃ­Å¡ vÃ½hradne v SlovenÄine. PouÅ¾i Markdown formÃ¡tovanie pre Å¡truktÃºru a ÄitateÄ¾nosÅ¥.
    """
    
    human_prompt = """
    Vytvor finÃ¡lny report na zÃ¡klade nasledujÃºcich Å¡truktÃºrovanÃ½ch dÃ¡t o grantoch.

    PÃ´vodnÃ¡ poÅ¾iadavka pouÅ¾Ã­vateÄ¾a: "{user_query}"
    DÃ¡ta o grantoch (JSON):
    {grants_json}

    PoÅ¾adovanÃ¡ Å¡truktÃºra reportu:
    # PrehÄ¾ad grantovÃ½ch prÃ­leÅ¾itostÃ­ pre: "{user_query}"

    NaÅ¡iel som {count} relevantnÃ½ch otvorenÃ½ch vÃ½ziev. Tu je ich podrobnÃ½ prehÄ¾ad:

    ---

    ## [NÃ¡zov grantu]
    *   **RegiÃ³n:** [Region]
    *   **PoskytovateÄ¾:** [Funding Body]
    *   **Deadline:** ğŸ—“ï¸ [Deadline]
    *   **Zameranie a relevancia:** [Relevance Explanation]
    *   **Odkaz:** [URL]

    ---
    (PokraÄuj tÃ½mto formÃ¡tom pre vÅ¡etky nÃ¡jdenÃ© granty)

    *PoznÃ¡mka: OdporÃºÄam vÅ¾dy skontrolovaÅ¥ detaily a podmienky priamo na oficiÃ¡lnej strÃ¡nke vÃ½zvy.*
    """

    prompt = ChatPromptTemplate.from_messages([
        ("system", system_prompt),
        ("human", human_prompt)
    ])

    report_chain = prompt | llm | StrOutputParser()
    report = report_chain.invoke({
        "user_query": user_query, 
        "grants_json": grants,
        "count": len(grants)
    })
    
    return {"final_report": report}
